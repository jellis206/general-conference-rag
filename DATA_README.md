# Data Files

## What's Included

**No CSV data files are included in the repository.** All embedding files can be easily regenerated by running the data pipeline.

This keeps the repository lightweight and avoids GitHub's file size limitations.

## What's Not Included

All embedding CSV files need to be generated locally:

- `free/free_talks.csv` (9.3 MB)
- `free/free_paragraphs.csv` (145 MB)
- `free/free_3_clusters.csv` (16 MB)
- `openai/openai_talks.csv` (23 MB)
- `openai/openai_paragraphs.csv` (563 MB)
- `openai/openai_3_clusters.csv` (58 MB)

## How to Regenerate Missing Files

If you need the full dataset, run the complete pipeline:

```bash
# 1. Activate virtual environment
source venv/bin/activate

# 2. Run the data generation pipeline
python scraper.py              # Scrape conference talks
python free_embeddings.py      # Generate free embeddings (includes paragraphs)
python openai_embeddings.py    # Generate OpenAI embeddings (includes paragraphs)
python clusters.py             # Generate cluster embeddings
```

**Total time**: ~10-15 minutes
**Requirements**: OpenAI API key in `.env` file

## File Sizes Reference

| File | Size | Purpose |
|------|------|---------|
| free_talks.csv | 9.3 MB | Full talk embeddings (free) |
| free_paragraphs.csv | 145 MB | Paragraph embeddings (free) |
| free_3_clusters.csv | 16 MB | Cluster embeddings (free) |
| openai_talks.csv | 23 MB | Full talk embeddings (OpenAI) |
| openai_paragraphs.csv | 563 MB | Paragraph embeddings (OpenAI) |
| openai_3_clusters.csv | 58 MB | Cluster embeddings (OpenAI) |

**Total when regenerated**: ~814 MB

## Why Not Include CSV Files?

1. **Easy to regenerate**: Running the pipeline takes only 10-15 minutes
2. **Keeps repo small**: Repository stays under 5 MB instead of 800+ MB
3. **Always fresh**: Users get the most recent conference talks
4. **No large file issues**: Avoids GitHub's file size limitations
